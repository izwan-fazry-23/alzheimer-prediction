{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dda456-0f07-423a-b768-d01e1f43d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897c7801-35c1-4065-9b3b-535afe8c6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject metadata\n",
    "subject_metadata = {\n",
    "    \"sub-001\": (\"F\", 57, 16), \"sub-002\": (\"F\", 78, 22), \"sub-003\": (\"M\", 70, 14), \"sub-004\": (\"F\", 67, 20),\n",
    "    \"sub-005\": (\"M\", 70, 22), \"sub-006\": (\"F\", 61, 14), \"sub-007\": (\"F\", 79, 20), \"sub-008\": (\"M\", 62, 16),\n",
    "    \"sub-009\": (\"F\", 77, 23), \"sub-010\": (\"M\", 69, 20), \"sub-011\": (\"M\", 71, 22), \"sub-012\": (\"M\", 63, 18),\n",
    "    \"sub-013\": (\"F\", 64, 20), \"sub-014\": (\"M\", 77, 14), \"sub-015\": (\"M\", 61, 18), \"sub-016\": (\"F\", 68, 14),\n",
    "    \"sub-017\": (\"F\", 61, 6),  \"sub-018\": (\"F\", 73, 23), \"sub-019\": (\"F\", 62, 14), \"sub-020\": (\"M\", 71, 4),\n",
    "    \"sub-021\": (\"M\", 79, 22), \"sub-022\": (\"F\", 68, 20), \"sub-023\": (\"M\", 60, 16), \"sub-024\": (\"F\", 69, 20),\n",
    "    \"sub-025\": (\"F\", 79, 20), \"sub-026\": (\"F\", 61, 18), \"sub-027\": (\"F\", 67, 16), \"sub-028\": (\"M\", 49, 20),\n",
    "    \"sub-029\": (\"F\", 53, 16), \"sub-030\": (\"F\", 56, 20), \"sub-031\": (\"F\", 67, 22), \"sub-032\": (\"F\", 59, 20),\n",
    "    \"sub-033\": (\"F\", 72, 20), \"sub-034\": (\"F\", 75, 18), \"sub-035\": (\"F\", 57, 22), \"sub-036\": (\"F\", 58, 9),\n",
    "    \"sub-037\": (\"M\", 57, 30), \"sub-038\": (\"M\", 62, 30), \"sub-039\": (\"M\", 70, 30), \"sub-040\": (\"M\", 61, 30),\n",
    "    \"sub-041\": (\"F\", 77, 30), \"sub-042\": (\"M\", 74, 30), \"sub-043\": (\"M\", 72, 30), \"sub-044\": (\"F\", 64, 30),\n",
    "    \"sub-045\": (\"F\", 70, 30), \"sub-046\": (\"M\", 63, 30), \"sub-047\": (\"F\", 70, 30), \"sub-048\": (\"M\", 65, 30),\n",
    "    \"sub-049\": (\"F\", 62, 30), \"sub-050\": (\"M\", 68, 30), \"sub-051\": (\"F\", 75, 30), \"sub-052\": (\"F\", 73, 30),\n",
    "    \"sub-053\": (\"M\", 70, 30), \"sub-054\": (\"M\", 78, 30), \"sub-055\": (\"M\", 67, 30), \"sub-056\": (\"F\", 64, 30),\n",
    "    \"sub-057\": (\"M\", 64, 30), \"sub-058\": (\"M\", 62, 30), \"sub-059\": (\"M\", 77, 30), \"sub-060\": (\"F\", 71, 30),\n",
    "    \"sub-061\": (\"F\", 63, 30), \"sub-062\": (\"M\", 67, 30), \"sub-063\": (\"M\", 66, 30), \"sub-064\": (\"M\", 66, 30),\n",
    "    \"sub-065\": (\"F\", 71, 30), \"sub-066\": (\"M\", 73, 20), \"sub-067\": (\"M\", 66, 24), \"sub-068\": (\"M\", 78, 25), \n",
    "    \"sub-069\": (\"M\", 70, 22), \"sub-070\": (\"F\", 67, 22), \"sub-071\": (\"M\", 62, 20), \"sub-072\": (\"M\", 65, 18), \n",
    "    \"sub-073\": (\"F\", 57, 22), \"sub-074\": (\"F\", 53, 20), \"sub-075\": (\"F\", 71, 22), \"sub-076\": (\"M\", 44, 24), \n",
    "    \"sub-077\": (\"M\", 61, 22), \"sub-078\": (\"M\", 62, 22), \"sub-079\": (\"F\", 60, 18), \"sub-080\": (\"F\", 71, 20), \n",
    "    \"sub-081\": (\"F\", 61, 18), \"sub-082\": (\"M\", 63, 27), \"sub-083\": (\"F\", 68, 20), \"sub-084\": (\"F\", 71, 24), \n",
    "    \"sub-085\": (\"M\", 64, 26), \"sub-086\": (\"M\", 49, 26), \"sub-087\": (\"M\", 73, 24), \"sub-088\": (\"M\", 55, 24)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c53ec0-c8ca-4781-821c-feb12aff6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Discrete Wavelet Transform coefficients\n",
    "def calculate_dwt_coefficients(signal, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(data=signal, wavelet=wavelet, level=level)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902dce07-f2aa-4958-b30f-cc5555c93f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Hjorth parameters\n",
    "def calculate_hjorth_parameters(signal):\n",
    "    first_deriv = np.diff(signal)\n",
    "    second_deriv = np.diff(first_deriv)\n",
    "    var_zero = np.var(signal)\n",
    "    var_d1 = np.var(first_deriv)\n",
    "    var_d2 = np.var(second_deriv)\n",
    "    \n",
    "    activity = var_zero\n",
    "    mobility = np.sqrt(var_d1 / var_zero)\n",
    "    complexity = np.sqrt((var_d2 / var_d1) / mobility)\n",
    "    \n",
    "    features = {}\n",
    "    features['hjorth_activity'] = activity\n",
    "    features['hjorth_mobility'] = mobility\n",
    "    features['hjorth_complexity'] = complexity\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af8046a-ff3a-42ec-ae14-a39ce8c7e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Shannon entropy\n",
    "def calculate_shannon_entropy(signal):\n",
    "    values, counts = np.unique(signal, return_counts=True)\n",
    "    prob = counts / len(signal)\n",
    "    shannon_entropy = -np.sum(prob * np.log2(prob))\n",
    "    return shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27099200-b546-43ef-992f-c38ed2354838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Sure entropy\n",
    "def calculate_sure_entropy(signal, threshold=0.1):\n",
    "    N = len(signal)\n",
    "    count = np.sum(np.abs(signal) <= threshold)\n",
    "    sure_entropy = N - count + np.sum(np.minimum(signal**2, threshold**2))\n",
    "    return sure_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d160461d-0439-4b05-b6b6-1179803394a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate statistical features for DWT coefficients\n",
    "def calculate_statistical_features(coeffs):\n",
    "    features = {}\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        prefix = f\"dwt_{i}\"\n",
    "        \n",
    "        # Hjorth parameters\n",
    "        hjorth_params = calculate_hjorth_parameters(coeff)\n",
    "        features[f\"hjorth_activity_{prefix}\"] = hjorth_params['hjorth_activity']\n",
    "        features[f\"hjorth_mobility_{prefix}\"] = hjorth_params['hjorth_mobility']\n",
    "        features[f\"hjorth_complexity_{prefix}\"] = hjorth_params['hjorth_complexity']\n",
    "        \n",
    "        # Shannon entropy\n",
    "        shannon_entropy = calculate_shannon_entropy(coeff)\n",
    "        features[f\"shannon_entropy_{prefix}\"] = shannon_entropy\n",
    "        \n",
    "        # Sure entropy\n",
    "        sure_entropy = calculate_sure_entropy(coeff)\n",
    "        features[f\"sure_entropy_{prefix}\"] = sure_entropy\n",
    "\n",
    "        # Variance\n",
    "        features[f\"var_{prefix}\"] = np.var(coeff)\n",
    "        \n",
    "        # Skewness\n",
    "        features[f\"skew_{prefix}\"] = stats.skew(coeff)\n",
    "        \n",
    "        # Kurtosis\n",
    "        features[f\"kurt_{prefix}\"] = stats.kurtosis(coeff)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f80df2-036d-491f-9d50-110c0dace258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(signals):\n",
    "    features = []\n",
    "    for signal in signals:\n",
    "        # Calculate DWT coefficients\n",
    "        coeffs = calculate_dwt_coefficients(signal)\n",
    "        \n",
    "        # Calculate statistical features\n",
    "        stats_features = calculate_statistical_features(coeffs)\n",
    "        features.extend(stats_features.values())\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f809e9-7924-4fb3-806f-8a8ec3bf76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to truncate data\n",
    "def truncate_data(data, max_samples):\n",
    "    return data[:max_samples]\n",
    "\n",
    "# Function to segment data into epochs\n",
    "def segment_data(data, epoch_length):\n",
    "    num_samples = data.shape[0]\n",
    "    num_epochs = num_samples // epoch_length\n",
    "    epochs = []\n",
    "    for i in range(num_epochs):\n",
    "        start_idx = i * epoch_length\n",
    "        end_idx = start_idx + epoch_length\n",
    "        epochs.append(data[start_idx:end_idx])\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4228689f-1eec-4498-9460-1c54f46dcd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channel labels\n",
    "channels = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T3', 'C3', 'Cz', 'C4', 'T4', 'T5', 'P3', 'Pz', 'P4', 'T6', 'O1', 'O2']\n",
    "\n",
    "# Adjusted Feature Labels\n",
    "selected_feature_types = ['hjorth_activity', 'hjorth_mobility', 'hjorth_complexity', 'shannon_entropy', 'sure_entropy', 'var', 'skew', 'kurt']\n",
    "dwt_labels = [f\"dwt_{i}\" for i in range(5)]\n",
    "selected_feature_labels = [f\"{feature_type}_{dwt}_{channel}\" for feature_type in selected_feature_types for dwt in dwt_labels for channel in channels]\n",
    "\n",
    "# Additional metadata labels\n",
    "additional_labels = ['epoch', 'subject', 'gender', 'age', 'class', 'mmse']\n",
    "final_labels = additional_labels + selected_feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ddea4ce-4726-4ceb-95d6-3911bacaf5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the duration to certain minutes\n",
    "desired_duration_minutes = 5.1\n",
    "\n",
    "# Convert the desired duration to the number of samples\n",
    "max_samples = int(desired_duration_minutes * 60 * 500)  # Convert minutes to samples\n",
    "\n",
    "# Set the epoch length\n",
    "epoch_length = 2 * 500  # Samples per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "651fd7fb-0ddd-4a9f-8353-3760ce58326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing all subjects' data\n",
    "folder_path = r\"C:\\Users\\Izwan\\Desktop\\alzheimer-prediction\\converted-files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed13036a-1b0a-49fc-8cea-058f3e7c805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: sub-001_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-002_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-003_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-004_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-005_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-006_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-007_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-008_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-009_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-010_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-011_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-012_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-013_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-014_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-015_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-016_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-017_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-018_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-019_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-020_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-021_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-022_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-023_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-024_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-025_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-026_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-027_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-028_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-029_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-030_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-031_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-032_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-033_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-034_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-035_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-036_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-037_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-038_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-039_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-040_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-041_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-042_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-043_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-044_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-045_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-046_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-047_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-048_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-049_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-050_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-051_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-052_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-053_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-054_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-055_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-056_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-057_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-058_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-059_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-060_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-061_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-062_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-063_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-064_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-065_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-066_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-067_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-068_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-069_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-070_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-071_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-072_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-073_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-074_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-075_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-076_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-077_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-078_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-079_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-080_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-081_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-082_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-083_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-084_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-085_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-086_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-087_task-eyesclosed_eeg.csv\n",
      "Reading file: sub-088_task-eyesclosed_eeg.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store all features\n",
    "all_features = []\n",
    "\n",
    "# Iterate over all files and directories in the folder\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            \n",
    "            # Extract subject ID from filename\n",
    "            subject_id = file.split(\"_\")[0]\n",
    "\n",
    "            # Extract metadata\n",
    "            gender, age, mmse = subject_metadata[subject_id]\n",
    "            classification = (\n",
    "                'A' if 1 <= int(subject_id.split('-')[1]) <= 36 else \n",
    "                'C' if 37 <= int(subject_id.split('-')[1]) <= 65 else \n",
    "                'F' if 66 <= int(subject_id.split('-')[1]) <= 88 else 'Unknown'\n",
    "            )\n",
    "                \n",
    "            # Read the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Reading file: {file}\")\n",
    "            data = pd.read_csv(file_path)\n",
    "        \n",
    "            # Truncate the data to the maximum number of samples\n",
    "            data = truncate_data(data, max_samples)\n",
    "            \n",
    "            # Segment the data into epochs\n",
    "            epochs = segment_data(data, epoch_length)\n",
    "            \n",
    "            # Process each epoch\n",
    "            for epoch_idx, epoch in enumerate(epochs):\n",
    "                subject_features = []\n",
    "                for channel in channels:\n",
    "                    if channel in data.columns:\n",
    "                        # Extract features for the channel\n",
    "                        subject_features.extend(extract_features([epoch[channel].values]))\n",
    "                    else:\n",
    "                        print(f\"Channel {channel} missing in file {file}.\")\n",
    "                        # Placeholder for missing features\n",
    "                        subject_features.extend([np.nan] * len(selected_feature_labels))\n",
    "                \n",
    "                # Combine metadata, epoch, and features into a single list\n",
    "                combined_features = [epoch_idx + 1, subject_id, gender, age, classification, mmse] + subject_features\n",
    "                all_features.append(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2d2c77-5af7-407a-bb9f-303b2a05dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted and saved to extracted-features-5min.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of features to a DataFrame\n",
    "df_features = pd.DataFrame(all_features, columns=final_labels)\n",
    "\n",
    "# Save the features to a CSV file\n",
    "output_csv_file = \"extracted-features.csv\"\n",
    "df_features.to_csv(output_csv_file, index=False)\n",
    "print(f\"Features extracted and saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
